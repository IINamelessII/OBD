Текстовый анализ (Text Mining, интеллектуальный анализ текста) — направление в искусственном интеллекте, целью которого является получение информации из коллекций текстовых документов, основываясь на применении эффективных в практическом плане методов машинного обучения и обработки естественного языка. Текстовый анализ перекликается с понятием интеллектуального анализа данных (ИАД), что выражает схожесть их целей, подходов к переработке информации и сфер применения; разница проявляется лишь в конечных методах, а также в том, что ИАД имеет дело с хранилищами и базами данных, а не электронными библиотеками и корпусами текстов.

Ключевыми группами задач ИАТ являются: категоризация текстов, извлечение информации и информационный поиск, обработка изменений в коллекциях текстов, а также разработка средств представления информации для пользователя.

# Этапы анализа текстов
Анализ структурированной информации, хранящейся в базах данных, требует предварительной обработки: проектирования БД, ввод информации по определенным правилам, размещение ее в специальных структурах (например, реляционных таблицах) и т. п. Стуктуризация требует немалых усилий, поэтому КПД анализа структурированной информации снижается. Также, из-за того, что не все виды данных можно структурировать без потери полезной информации, например, текстовые документы,они хранятся в БД без преобразований, как текстовые поля (BLOB-поля). Неструктурированность текста не позволяет использовать алгоритмы Data Mining. Собственно, почему и был выделен текстовый анализ.

Методы анализа в неструктурированных текстах лежат на стыке нескольких областей: Data Mining, обработка естественных языков, поиск информации, извлечение информации и управление знаниями. В общем случае документы могут быть сложными и большими и включать в себя не только текст, но и графическую информацию: электронная почта, web-страницы, нормативные документы и т.п.

Процесс анализа текстовых документов можно представить как последовательность нескольких шагов.
1. Поиск информации - то есть выбор документов, которые надо проанализировать. Можно делать вручную, но при большом количестве данных необходимо использовать варианты автоматизированного отбора по заданным критериям. 
2. Предварительная обработка документов - простые, но важные преобразования текста: удаление лишних слов и придание тексту более строгой формы.
3. Извлечение информации - выделение в них ключевых понятий, над которыми в дальнейшем будет выполняться анализ.
4. Применение методов Text Mining. На данном шаге извлекаются шаблоны и отношения, имеющиеся в текстах.
5. Интерпретация результатов. Заключается в представлении результатов на естественном языке или в визуализации в графическом виде.

Визуализация также может быть использована как средство анализа текста. Для этого извлекаются ключевые понятия, которые и представляются в графическом виде. Такой подход помогает пользователю быстро идентифицировать главные темы и понятия, а также определить их важность. 

# Предварительная обработка текста
Одной из главных проблем анализа текстов является большое количество слов в документе. Если каждое из этих слов подвергать анализу, то время поиска новых знаний резко возрастет и вряд ли будет удовлетворять требованиям пользователей. В то же время очевидно, что не все слова в тексте несут полезную информацию. Кроме того, в силу гибкости естественных языков формально различные слова (синонимы и т. п.) на самом деле означают одинаковые понятия. Таким образом, удаление неинформативных слов, а также приведение близких по смыслу слов к единой форме значительно сокращают время анализа текстов. 
Обычно используют следующие приемы удаления неинформативных слов и повышения строгости текстов:
1. *удаление стоп-слов*. Стоп-словами называются слова, которые являются вспомогательными и несут мало информации о содержании документа.
Обычно заранее составляются списки таких слов, и в процессе предварительной обработки они удаляются из текста. Типичным примером таких
слов являются вспомогательные слова и артикли, например: "так как", "кроме того" и т. п.;
2. *стемминг* — морфологический поиск. Он заключается в преобразовании каждого слова к его нормальной форме. Нормальная форма исключает 
склонение слова, множественную форму, особенности устной речи и т. п. Например, слова "сжатие" и "сжатый" должны быть преобразованы в нормальную форму слова "сжимать". Алгоритмы морфологического разбора учитывают языковые особенности и вследствие этого являются языковозависимыми алгоритмами;
3. *N-граммы* — это альтернатива морфологическому разбору и удалению стоп-слов. N-грамма — это часть строки, состоящая из N символов. Например, слово "дата" может быть представлено 3-граммой "_да", "дат", "ата", "та_" или 4-граммой "_дат", "дата", "ата_", где символ подчеркивания заменяет предшествующий или замыкающий слово пробел. По сравнению со стеммингом или удалением стоп-слов, N-граммы менее чувствительны к грамматическим и типографическим ошибкам. Кроме того, N-граммы не требуют лингвистического представления слов, что делает данный прием более независимым от языка. Однако N-граммы, позволяя сделать текст более строгим, не решают проблему уменьшения количества неинформативных слов;
4. *приведение регистра*. Этот прием заключается в преобразовании всех символов к верхнему или нижнему регистру. Например, все слова "текст", "Текст", "ТЕКСТ" приводятся к нижнему регистру "текст".


